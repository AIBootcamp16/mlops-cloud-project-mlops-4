import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.graph_objects as go
import boto3
from io import BytesIO
import os
from dotenv import load_dotenv
import httpx
import asyncio

load_dotenv()

# -------------------------
# AWS í™˜ê²½ë³€ìˆ˜
# -------------------------
AWS_ACCESS_KEY_ID = os.environ.get("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.environ.get("AWS_SECRET_ACCESS_KEY")
BUCKET_NAME = os.environ.get("BUCKET_NAME")

# AWS ìê²© ì¦ëª… ì²´í¬
if not all([AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, BUCKET_NAME]):
    st.warning("AWS í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    USE_AWS = False
else:
    USE_AWS = True
    s3_client = boto3.client(
        "s3",
        aws_access_key_id=AWS_ACCESS_KEY_ID,
        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
    )

# -------------------------
# S3 ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# -------------------------
def load_s3_parquet_hours(bucket_name: str, coins: list, hours: int = 30):
    if not USE_AWS:
        return {coin: pd.DataFrame() for coin in coins}
    
    now_utc = datetime.utcnow().replace(minute=0, second=0, microsecond=0)
    start_utc = now_utc - timedelta(hours=hours)
    date_list = pd.date_range(start=start_utc.date(), end=now_utc.date()).strftime("%Y-%m-%d").tolist()
    dfs = []

    for date in date_list:
        prefix = f"upbit_ticker/{date}/"
        try:
            response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
        except Exception as e:
            print(f"S3 ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            continue

        if "Contents" not in response:
            continue

        for obj in response["Contents"]:
            key = obj["Key"]
            if key.endswith("/"):
                continue
            try:
                file_obj = s3_client.get_object(Bucket=bucket_name, Key=key)
                df_temp = pd.read_parquet(BytesIO(file_obj['Body'].read()))
                df_temp['event_timestamp'] = pd.to_datetime(df_temp['timestamp'], unit='ms') + pd.Timedelta(hours=9)

                start_kst = start_utc + timedelta(hours=9)
                end_kst = now_utc + timedelta(hours=9)
                df_temp = df_temp[(df_temp['event_timestamp'] >= start_kst) & (df_temp['event_timestamp'] <= end_kst)]

                if not df_temp.empty:
                    dfs.append(df_temp)
                    print(f"Loaded ({hours}h range): {key}")
            except Exception as e:
                print(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {key}: {e}")
                continue

    if len(dfs) == 0:
        return {coin: pd.DataFrame() for coin in coins}

    df = pd.concat(dfs, ignore_index=True)
    df['event_hour'] = df['event_timestamp'].dt.floor('H')

    coin_dfs = {}
    for coin in coins:
        coin_df = df[df['market'] == coin].groupby('event_hour').first().reset_index()
        coin_dfs[coin] = coin_df

    return coin_dfs

def load_s3_parquet_incremental(bucket_name: str, coins: list, existing_data: dict, last_hour: datetime):
    """ì¦ë¶„ ë°ì´í„°ë§Œ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    if not USE_AWS:
        return existing_data
    
    now_utc = datetime.utcnow().replace(minute=0, second=0, microsecond=0)
    
    # ë§ˆì§€ë§‰ ë¡œë“œ ì‹œê°ê³¼ í˜„ì¬ ì‹œê°ì˜ ì°¨ì´ ê³„ì‚°
    last_hour_utc = last_hour.replace(tzinfo=None) - timedelta(hours=9)  # KST to UTC
    hours_diff = int((now_utc - last_hour_utc).total_seconds() / 3600)
    
    if hours_diff <= 0:
        print("ì¦ë¶„ ë°ì´í„° ì—†ìŒ - ê¸°ì¡´ ë°ì´í„° ìœ ì§€")
        return existing_data
    
    print(f"ì¦ë¶„ ë°ì´í„° ë¡œë“œ: ìµœê·¼ {hours_diff}ì‹œê°„")
    
    # ì¦ë¶„ ë°ì´í„°ë§Œ ë¡œë“œ
    start_utc = now_utc - timedelta(hours=hours_diff)
    date_list = pd.date_range(start=start_utc.date(), end=now_utc.date()).strftime("%Y-%m-%d").tolist()
    dfs = []

    for date in date_list:
        prefix = f"upbit_ticker/{date}/"
        try:
            response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
        except Exception as e:
            print(f"S3 ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            continue

        if "Contents" not in response:
            continue

        for obj in response["Contents"]:
            key = obj["Key"]
            if key.endswith("/"):
                continue
            try:
                file_obj = s3_client.get_object(Bucket=bucket_name, Key=key)
                df_temp = pd.read_parquet(BytesIO(file_obj['Body'].read()))
                df_temp['event_timestamp'] = pd.to_datetime(df_temp['timestamp'], unit='ms') + pd.Timedelta(hours=9)

                start_kst = start_utc + timedelta(hours=9)
                end_kst = now_utc + timedelta(hours=9)
                df_temp = df_temp[(df_temp['event_timestamp'] >= start_kst) & (df_temp['event_timestamp'] <= end_kst)]

                if not df_temp.empty:
                    dfs.append(df_temp)
                    print(f"Incremental load: {key}")
            except Exception as e:
                print(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {key}: {e}")
                continue

    if len(dfs) == 0:
        print("ì¦ë¶„ ë°ì´í„° ì—†ìŒ")
        return existing_data

    df_new = pd.concat(dfs, ignore_index=True)
    df_new['event_hour'] = df_new['event_timestamp'].dt.floor('H')

    # ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©
    updated_coin_dfs = {}
    for coin in coins:
        new_coin_df = df_new[df_new['market'] == coin].groupby('event_hour').first().reset_index()
        
        if coin in existing_data and not existing_data[coin].empty:
            # ê¸°ì¡´ ë°ì´í„°ì™€ í•©ì¹˜ê³  ìµœê·¼ 30ì‹œê°„ë§Œ ìœ ì§€
            combined = pd.concat([existing_data[coin], new_coin_df], ignore_index=True)
            combined = combined.drop_duplicates(subset=['event_hour'], keep='last')
            combined = combined.sort_values('event_hour').tail(30).reset_index(drop=True)
            updated_coin_dfs[coin] = combined
        else:
            updated_coin_dfs[coin] = new_coin_df

    return updated_coin_dfs

# -------------------------
# ì˜ˆì¸¡ API í˜¸ì¶œ í•¨ìˆ˜ë“¤
# -------------------------
async def fetch_prediction_async(coin: str, model: str, df: pd.DataFrame):
    """ë¹„ë™ê¸° ì˜ˆì¸¡ API í˜¸ì¶œ"""
    url = "http://localhost:8000/predict/lstm"
    
    # DataFrameì„ dictë¡œ ë³€í™˜ (ìµœê·¼ 30ì‹œê°„ ë°ì´í„° ì „ì†¡)
    df_clean = df.tail(30).copy()
    
    # Timestampë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°
    for col in df_clean.columns:
        if pd.api.types.is_datetime64_any_dtype(df_clean[col]):
            df_clean[col] = df_clean[col].dt.strftime('%Y-%m-%d %H:%M:%S')
    
    df_payload = df_clean.to_dict(orient="records")

    payload = {
        "coin": coin,
        "model": model,
        "recent_data": df_payload
    }

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload, timeout=10.0)
            response.raise_for_status()
            return response.json()
    except httpx.ConnectError:
        return {"error": "connection_failed", "message": "ì˜ˆì¸¡ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
    except httpx.TimeoutException:
        return {"error": "timeout", "message": "ì˜ˆì¸¡ API ì‘ë‹µ ì‹œê°„ ì´ˆê³¼"}
    except Exception as e:
        return {"error": "unknown", "message": f"ì˜ˆì¸¡ API í˜¸ì¶œ ì‹¤íŒ¨: {e}"}

def fetch_prediction(coin: str, model: str, df: pd.DataFrame):
    """ë™ê¸° ë˜í¼ í•¨ìˆ˜"""
    try:
        return asyncio.run(fetch_prediction_async(coin, model, df))
    except Exception as e:
        return {"error": "asyncio_failed", "message": f"ë¹„ë™ê¸° í˜¸ì¶œ ì‹¤íŒ¨: {e}"}

def generate_dummy_prediction(current_price: float, volatility: float, model: str):
    """ë”ë¯¸ ì˜ˆì¸¡ê°’ ìƒì„±"""
    # ëª¨ë¸ë³„ íŠ¹ì„± ë°˜ì˜
    model_factors = {
        "LSTM": {"trend": 0.02, "noise": 0.8},
        "GRU": {"trend": 0.015, "noise": 0.75},
        "Prophet": {"trend": 0.01, "noise": 0.9},
        "LightGBM": {"trend": 0.025, "noise": 0.7}
    }
    
    factor = model_factors.get(model, {"trend": 0.02, "noise": 0.8})
    
    # ì˜ˆì¸¡ ê°€ê²© (ì•½ê°„ì˜ ìƒìŠ¹ ë°”ì´ì–´ìŠ¤ + ëœë¤ ë…¸ì´ì¦ˆ)
    trend = np.random.normal(factor["trend"], volatility * 0.5)
    pred_price = current_price * (1 + trend)
    
    # ì‹ ë¢°ë„ (ëª¨ë¸ë³„ë¡œ ë‹¤ë¥´ê²Œ)
    base_confidence = factor["noise"]
    confidence = base_confidence + np.random.uniform(-0.1, 0.1)
    confidence = max(0.6, min(0.95, confidence))
    
    return {
        'predicted_price': pred_price,
        'confidence': confidence,
        'model_used': model,
        'metrics': {
            'rmse': np.random.uniform(15000, 45000),
            'mae': np.random.uniform(8000, 25000),
            'r2': np.random.uniform(0.75, 0.92)
        }
    }

def create_dummy_data(coin: str, period: int = 30):
    """ë”ë¯¸ ë°ì´í„° ìƒì„± í•¨ìˆ˜"""
    now = datetime.now()
    timestamps = [now - timedelta(hours=i) for i in range(period)][::-1]
    
    # ì½”ì¸ë³„ ê¸°ë³¸ ê°€ê²© ì„¤ì •
    base_prices = {
        'KRW-BTC': 73000000,
        'KRW-ETH': 3500000,
        'KRW-DOGE': 180,
        'KRW-XRP': 700
    }
    
    base_price = base_prices.get(coin, 50000)
    # ì¢€ ë” í˜„ì‹¤ì ì¸ ê°€ê²© ë³€ë™
    price_changes = np.random.randn(period) * base_price * 0.005  # 0.5% ë³€ë™ì„±
    prices = base_price + np.cumsum(price_changes)
    volumes = np.random.uniform(50, 500, period)  # ê±°ë˜ëŸ‰
    
    return pd.DataFrame({
        "event_hour": timestamps,
        "trade_price": prices,
        "trade_volume": volumes
    })

# -------------------------
# Streamlit ì•± êµ¬ì„±
# -------------------------
st.set_page_config(page_title="Bitcoin ì˜ˆì¸¡ ì‚¬ì´íŠ¸", layout="wide")

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ ì´ˆê¸°í™” (ë°ì´í„° ë° ë§ˆì§€ë§‰ ë¡œë“œ ì‹œê°„ ì €ì¥)
if 'coin_data' not in st.session_state:
    st.session_state.coin_data = None
    st.session_state.last_load_hour = None

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.header("âš™ï¸ ì„¤ì •")
coins = ['KRW-BTC', 'KRW-ETH', 'KRW-DOGE', 'KRW-XRP']
selected_coin = st.sidebar.selectbox("ì½”ì¸ ì„ íƒ", coins)
data_load_hours = 30  # ë°ì´í„° ë¡œë“œ ì‹œê°„
display_hours = 24     # ì‹œê°í™” ì‹œê°„
model = st.sidebar.selectbox("ì˜ˆì¸¡ ëª¨ë¸ ì„ íƒ", ["LSTM", "GRU", "Prophet", "LightGBM"])

# -------------------------
# ìºì‹±ëœ ë°ì´í„° ë¡œë“œ
# -------------------------
@st.cache_data(ttl=3600)
def load_coin_data_initial(coin_list, hours):
    """ì´ˆê¸° ì „ì²´ ë°ì´í„° ë¡œë“œ"""
    return load_s3_parquet_hours(BUCKET_NAME, coin_list, hours=hours)

def load_coin_data_smart(coin_list, hours):
    """ìŠ¤ë§ˆíŠ¸ ë°ì´í„° ë¡œë“œ: ì´ˆê¸°ì—ëŠ” ì „ì²´, ì´í›„ì—ëŠ” ì¦ë¶„ë§Œ"""
    current_hour_dt = datetime.now().replace(minute=0, second=0, microsecond=0)
    
    # ì²« ë¡œë“œì´ê±°ë‚˜ ì„¸ì…˜ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
    if st.session_state.coin_data is None or st.session_state.last_load_hour is None:
        print("ì´ˆê¸° ë°ì´í„° ë¡œë“œ (ì „ì²´ 30ì‹œê°„)")
        coin_dfs = load_coin_data_initial(coin_list, hours)
        st.session_state.coin_data = coin_dfs
        st.session_state.last_load_hour = current_hour_dt
        return coin_dfs
    
    # ì‹œê°„ì´ ë°”ë€Œì§€ ì•Šì•˜ìœ¼ë©´ ê¸°ì¡´ ë°ì´í„° ë°˜í™˜
    if st.session_state.last_load_hour == current_hour_dt:
        print("ìºì‹œëœ ë°ì´í„° ì‚¬ìš©")
        return st.session_state.coin_data
    
    # ì‹œê°„ì´ ë°”ë€Œì—ˆìœ¼ë©´ ì¦ë¶„ ë°ì´í„°ë§Œ ë¡œë“œ
    print(f"ì¦ë¶„ ë°ì´í„° ë¡œë“œ ì‹œì‘: {st.session_state.last_load_hour} -> {current_hour_dt}")
    updated_data = load_s3_parquet_incremental(
        BUCKET_NAME, 
        coin_list, 
        st.session_state.coin_data, 
        st.session_state.last_load_hour
    )
    st.session_state.coin_data = updated_data
    st.session_state.last_load_hour = current_hour_dt
    return updated_data

# ì œëª©ê³¼ ë²„íŠ¼
col_title, col_button = st.columns([8, 2])
with col_title:
    st.title("ğŸš€ Bitcoin 1ì‹œê°„ ë‹¨ìœ„ ê°€ê²© ì˜ˆì¸¡")
with col_button:
    predict_btn = st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", help="ìµœì‹  ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸")

# -------------------------
# ë°ì´í„° ë¡œë“œ
# -------------------------
with st.spinner("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
    try:
        coin_dfs = load_coin_data_smart(coins, data_load_hours)
        if USE_AWS:
            if st.session_state.last_load_hour:
                load_type = "ì¦ë¶„" if st.session_state.last_load_hour < datetime.now().replace(minute=0, second=0, microsecond=0) else "ìºì‹œ"
                st.success(f"S3 ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ({load_type})")
            else:
                st.success("S3 ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
        else:
            st.info("ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        coin_dfs = {coin: pd.DataFrame() for coin in coins}

# -------------------------
# ì„ íƒ ì½”ì¸ ë°ì´í„° ì²˜ë¦¬
# -------------------------
df = coin_dfs.get(selected_coin, pd.DataFrame())

# ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ ìƒì„±
if df.empty:
    st.warning("ì„ íƒí•œ ì½”ì¸ì˜ 30ì‹œê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    df = create_dummy_data(selected_coin, data_load_hours)

# ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ê²½ìš° ì²´í¬
if len(df) < 2:
    st.error("ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    st.stop()

# -------------------------
# ì˜ˆì¸¡ ì‹¤í–‰
# -------------------------
@st.cache_data(ttl=300)  # 5ë¶„ê°„ ìºì‹œ
def get_cached_prediction(coin: str, model: str, data_hash: str, current_hour: str):
    """ìºì‹œëœ ì˜ˆì¸¡ ê²°ê³¼ - í˜„ì¬ ì‹œê°(ì‹œê°„)ì´ ë°”ë€Œë©´ ìë™ìœ¼ë¡œ ìƒˆë¡œ ìš”ì²­"""
    # ì „ì—­ df ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ API í˜¸ì¶œ
    result = fetch_prediction(coin, model, df)
    return result

# í˜„ì¬ ì‹œê°(ì‹œê°„ ë‹¨ìœ„)ì„ ìºì‹± í‚¤ì— í¬í•¨
current_hour = datetime.now().strftime("%Y-%m-%d %H:00:00")

# ë°ì´í„° í•´ì‹œ ìƒì„± (ìºì‹± í‚¤)
data_hash = hash(str(df['trade_price'].values.tobytes()) + selected_coin + model)

# ì˜ˆì¸¡ ìƒíƒœ í‘œì‹œ
prediction_status = st.empty()

# ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ì´ ëˆŒë ¸ì„ ë•Œ ìºì‹œ í´ë¦¬ì–´ ë° ì¦ë¶„ ë°ì´í„° ë¡œë“œ
if predict_btn:
    get_cached_prediction.clear()
    # í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ê°•ì œ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
    current_hour_for_refresh = datetime.now().replace(minute=0, second=0, microsecond=0)
    if st.session_state.last_load_hour and st.session_state.last_load_hour < current_hour_for_refresh:
        st.session_state.last_load_hour = None  # ì¦ë¶„ ë¡œë“œ ê°•ì œ ì‹¤í–‰
    st.rerun()

# ì˜ˆì¸¡ ì‹¤í–‰
with st.spinner("ğŸ”® ì˜ˆì¸¡ ì¤‘..."):
    try:
        prediction_result = get_cached_prediction(selected_coin, model, str(data_hash), current_hour)
        
        # ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬
        if prediction_result and 'predicted_price' in prediction_result:
            prediction_status.success("âœ… AI ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ!")
            prediction_source = "ğŸ¤– AI ëª¨ë¸"
            use_ai_prediction = True
        elif prediction_result and 'error' in prediction_result:
            # ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
            error_msg = prediction_result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
            prediction_status.warning(f"ğŸ”„ {error_msg} - í†µê³„ ê¸°ë°˜ ì˜ˆì¸¡ ì‚¬ìš©")
            
            # í†µê³„ì  ì˜ˆì¸¡ ìƒì„±
            current_price = df["trade_price"].iloc[-1]
            volatility = df["trade_price"].pct_change().std()
            prediction_result = generate_dummy_prediction(current_price, volatility, model)
            prediction_source = "ğŸ“Š í†µê³„ ëª¨ë¸"
            use_ai_prediction = False
        else:
            prediction_status.info("ğŸ”„ ì˜ˆì¸¡ ì„œë²„ ì‘ë‹µ ì—†ìŒ - í†µê³„ ê¸°ë°˜ ì˜ˆì¸¡ ì‚¬ìš©")
            current_price = df["trade_price"].iloc[-1]
            volatility = df["trade_price"].pct_change().std()
            prediction_result = generate_dummy_prediction(current_price, volatility, model)
            prediction_source = "ğŸ“Š í†µê³„ ëª¨ë¸"
            use_ai_prediction = False
            
    except Exception as e:
        st.error(f"ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
        current_price = df["trade_price"].iloc[-1]
        volatility = df["trade_price"].pct_change().std() if len(df) > 1 else 0.02
        prediction_result = generate_dummy_prediction(current_price, volatility, model)
        prediction_status.error("âŒ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì˜¤ë¥˜ - ê¸°ë³¸ê°’ ì‚¬ìš©")
        prediction_source = "ğŸ”§ ê¸°ë³¸ ëª¨ë¸"
        use_ai_prediction = False

# -------------------------
# ì˜ˆì¸¡ê°’ ê³„ì‚°
# -------------------------
pred_price = prediction_result['predicted_price']
prediction_confidence = prediction_result.get('confidence', 0.85)
current_price = df["trade_price"].iloc[-1]
pred_change = (pred_price - current_price) / current_price * 100

# -------------------------
# ë©”íŠ¸ë¦­ ì¹´ë“œ
# -------------------------
col1, col2, col3 = st.columns(3)

prev_price = df['trade_price'].iloc[-2] if len(df) >= 2 else current_price
price_change = (current_price - prev_price) / prev_price * 100 if prev_price != 0 else 0

col1.metric(
    "í˜„ì¬ ê°€ê²©",
    f"{current_price:,.0f}",
    f"{price_change:.2f}%"
)
col2.metric("24h ê±°ë˜ëŸ‰", f"{df['trade_volume'].sum():,.5f}")

# ì˜ˆì¸¡ ë°©í–¥ì— ë”°ë¥¸ ìƒ‰ìƒ í‘œì‹œ
pred_color = "normal"
if abs(pred_change) > 2:
    pred_color = "inverse" if pred_change < 0 else "normal"

col3.metric(
    "1ì‹œê°„ ë’¤ ì˜ˆì¸¡", 
    f"{pred_price:,.0f}", 
    f"{pred_change:.2f}%",
    delta_color=pred_color,
    help=f"{prediction_source} (ì‹ ë¢°ë„: {prediction_confidence:.1%})"
)

# -------------------------
# ì˜ˆì¸¡ ì‹ ë¢°ë„ í‘œì‹œ
# -------------------------
confidence_col1, confidence_col2 = st.columns([3, 1])
with confidence_col1:
    st.progress(prediction_confidence, text=f"ì˜ˆì¸¡ ì‹ ë¢°ë„: {prediction_confidence:.1%}")
with confidence_col2:
    if use_ai_prediction:
        st.success("ğŸŸ¢ AI í™œì„±")
    else:
        st.warning("ğŸŸ¡ í†µê³„ ëª¨ë“œ")

# -------------------------
# Plotly ì°¨íŠ¸ (24ì‹œê°„ ë°ì´í„°ë§Œ ì‹œê°í™”)
# -------------------------
# ì‹œê°í™”ìš©ìœ¼ë¡œ ìµœê·¼ 24ì‹œê°„ ë°ì´í„°ë§Œ ì¶”ì¶œ
df_display_chart = df.tail(display_hours).copy()

fig = go.Figure()

# ì‹¤ì œ ê°€ê²© ë¼ì¸
fig.add_trace(go.Scatter(
    x=df_display_chart["event_hour"],
    y=df_display_chart["trade_price"],
    mode="lines+markers",
    name="ì‹¤ì œ ê°€ê²©",
    line=dict(color="blue", width=2),
    marker=dict(size=4)
))

# ì˜ˆì¸¡ ì‹œì  ì¶”ê°€
next_hour = df_display_chart["event_hour"].iloc[-1] + timedelta(hours=1)
pred_color_line = "red" if pred_change > 0 else "orange"

fig.add_trace(go.Scatter(
    x=[df_display_chart["event_hour"].iloc[-1], next_hour],
    y=[current_price, pred_price],
    mode="lines+markers+text",
    name="ì˜ˆì¸¡ ê°€ê²©",
    line=dict(color=pred_color_line, dash="dash", width=3),
    marker=dict(color=pred_color_line, size=8),
    text=[None, f"{pred_price:,.0f}ì›"],
    textposition="top center",
    textfont=dict(size=12, color=pred_color_line)
))

# ì‹ ë¢°êµ¬ê°„ ì¶”ê°€ (ì˜ˆì¸¡ê°’ ê¸°ì¤€ Â±5%)
confidence_band = pred_price * 0.05
fig.add_trace(go.Scatter(
    x=[next_hour, next_hour, next_hour],
    y=[pred_price - confidence_band, pred_price, pred_price + confidence_band],
    mode="markers",
    name="ì‹ ë¢°êµ¬ê°„",
    marker=dict(color=pred_color_line, size=3, opacity=0.3),
    showlegend=False
))

fig.update_layout(
    title=f"{selected_coin} ìµœê·¼ {display_hours}ì‹œê°„ ê°€ê²© ì¶”ì´ & ì˜ˆì¸¡",
    xaxis_title="ì‹œê°„",
    yaxis_title="ê°€ê²© (KRW)",
    template="plotly_white",
    height=500,
    hovermode='x unified'
)

st.plotly_chart(fig, use_container_width=True)

# -------------------------
# ë°ì´í„° í…Œì´ë¸”
# -------------------------
st.subheader("ğŸ“Š ìµœê·¼ ë°ì´í„°")
df_display = df.tail(24).copy()
df_display["event_hour"] = df_display["event_hour"].dt.strftime("%Y-%m-%d %H:%M")
df_display["trade_price"] = df_display["trade_price"].round(0)
df_display["trade_volume"] = df_display["trade_volume"].round(2)
df_display = df_display.set_index("event_hour")
st.dataframe(df_display, height=400, use_container_width=True)

# -------------------------
# ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ
# -------------------------
st.subheader("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ")

# ì˜ˆì¸¡ ê²°ê³¼ì˜ ì„±ëŠ¥ ì§€í‘œ ì‚¬ìš©
metrics = prediction_result.get('metrics', {})
metrics_df = pd.DataFrame({
    "ëª¨ë¸": [model],
    "RMSE": [f"{metrics.get('rmse', 30000):,.0f}"],
    "MAE": [f"{metrics.get('mae', 20000):,.0f}"],
    "RÂ²": [f"{metrics.get('r2', 0.85):.3f}"],
    "ì˜ˆì¸¡ ì‹ ë¢°ë„": [f"{prediction_confidence:.1%}"],
    "ë°ì´í„° ì†ŒìŠ¤": [prediction_source]
})

st.dataframe(metrics_df, height=100, use_container_width=True)

# -------------------------
# ì‹œìŠ¤í…œ ìƒíƒœ
# -------------------------
st.subheader("ğŸ”§ ì‹œìŠ¤í…œ ìƒíƒœ")
status_cols = st.columns(3)

with status_cols[0]:
    if USE_AWS:
        st.success("ğŸŸ¢ AWS S3 ì—°ê²°ë¨")
    else:
        st.info("ğŸ”µ ë¡œì»¬ ë”ë¯¸ ë°ì´í„°")

with status_cols[1]:
    if use_ai_prediction:
        st.success("ğŸŸ¢ AI ì˜ˆì¸¡ ëª¨ë¸ í™œì„±í™”")
    else:
        st.warning("ğŸŸ¡ í†µê³„ ê¸°ë°˜ ì˜ˆì¸¡ ì‚¬ìš©")

with status_cols[2]:
    data_quality = "ì–‘í˜¸" if len(df) >= 20 else "ë¶€ì¡±"
    if len(df) >= 20:
        st.success(f"ğŸŸ¢ ë°ì´í„° í’ˆì§ˆ: {data_quality}")
    else:
        st.warning(f"ğŸŸ¡ ë°ì´í„° í’ˆì§ˆ: {data_quality}")

# í‘¸í„°
st.markdown("---")
footer_col1, footer_col2 = st.columns([3, 1])
with footer_col1:
    st.markdown("ğŸ¤– **AI ê¸°ë°˜ ì•”í˜¸í™”í ê°€ê²© ì˜ˆì¸¡ ì‹œìŠ¤í…œ** | ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸")
with footer_col2:
    st.caption(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {current_hour}")

# ìë™ ìƒˆë¡œê³ ì¹¨ ì˜µì…˜ (ì„ íƒì‚¬í•­)
if st.sidebar.checkbox("ìë™ ìƒˆë¡œê³ ì¹¨ (30ì´ˆ)", value=False):
    import time
    time.sleep(30)
    st.rerun()